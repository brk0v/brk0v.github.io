<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Essential Page Cache theory
  #


    
        Last updated: Oct 2025
    

Contents

Read requests
Write requests


First of all, let’s start with a bunch of reasonable questions about Page Cache:

What is the Linux Page Cache?
What problems does it solve?
Why do we call it «Page» Cache ?

In essence, the Page Cache is a part of the Virtual File System (VFS) whose primary purpose, as you can guess, is improving the IO latency of read and write operations. A write-back cache algorithm is a core building block of the Page Cache."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://biriukov.dev/docs/page-cache/2-essential-page-cache-theory/"><meta property="og:site_name" content="Viacheslav Biriukov"><meta property="og:title" content="Essential Linux Page Cache theory"><meta property="og:description" content="Essential Page Cache theory # Last updated: Oct 2025 Contents
Read requests Write requests First of all, let’s start with a bunch of reasonable questions about Page Cache:
What is the Linux Page Cache? What problems does it solve? Why do we call it «Page» Cache ? In essence, the Page Cache is a part of the Virtual File System (VFS) whose primary purpose, as you can guess, is improving the IO latency of read and write operations. A write-back cache algorithm is a core building block of the Page Cache."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>Essential Linux Page Cache theory | Viacheslav Biriukov</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=stylesheet href=/book.min.1e13c2d8521416f2409b2e0e47b515c4ee90f2718cddd31ea96d2f739bc9d7e1.css integrity="sha256-HhPC2FIUFvJAmy4OR7UVxO6Q8nGM3dMeqW0vc5vJ1+E=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.7e97a0cfe832281a8126c98203712496c0cabeb060b5bfb911edaf36327ad30a.js integrity="sha256-fpegz+gyKBqBJsmCA3EklsDKvrBgtb+5Ee2vNjJ60wo=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-599VSLESJL"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-599VSLESJL")</script><link rel=stylesheet href=/my_css/cookie.css><link rel=stylesheet href=/my_css/copy-code.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>Viacheslav Biriukov</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><span>Linux Page Cache series</span><ul><li><a href=/docs/page-cache/0-linux-page-cache-for-sre/>0. Linux Page Cache for SRE</a></li><li><a href=/docs/page-cache/1-prepare-environment-for-experiments/>1. Prepare environments</a></li><li><a href=/docs/page-cache/2-essential-page-cache-theory/ class=active>2. Essential theory</a></li><li><a href=/docs/page-cache/3-page-cache-and-basic-file-operations/>3. Basic file operations</a></li><li><a href=/docs/page-cache/4-page-cache-eviction-and-page-reclaim/>4. Eviction and page reclaim</a></li><li><a href=/docs/page-cache/5-more-about-mmap-file-access/>5. More about mmap()</a></li><li><a href=/docs/page-cache/6-cgroup-v2-and-page-cache/>6. cgroup v2</a></li><li><a href=/docs/page-cache/7-how-much-memory-my-program-uses-or-the-tale-of-working-set-size/>7. Unique set and working set</a></li><li><a href=/docs/page-cache/8-direct-io-dio/>8. Direct IO</a></li><li><a href=/docs/page-cache/9-advanced-page-cache-observability-and-troubleshooting-tools/>9. Advanced tools</a></li></ul></li></ul><div style=margin-top:30px;margin-bottom:30px><b>More recent series:</b><ul><li><a href=/rust-tokio-io/>1. Async Rust & Tokio I/O Streams: Backpressure, Concurrency, and Ergonomics&nbsp;<span style="padding:0 2px;border-radius:2px;background-color:#e84118;color:#f0f8ff">new</span></li><li><a href=/docs/resolver-dual-stack-application/0-sre-should-know-about-gnu-linux-resolvers-and-dual-stack-applications/>2. Resolvers and Dual-Stack applications</li><li><a href=/docs/page-cache/0-linux-page-cache-for-sre/>3. Linux Page Cache mini book</li><li><a href=/docs/fd-pipe-session-terminal/0-sre-should-know-about-gnu-linux-shell-related-internals-file-descriptors-pipes-terminals-user-sessions-process-groups-and-daemons>4. File descriptors, pipes, terminals, user sessions, process groups and daemons</li></ul></div><div style=margin-top:30px;margin-bottom:30px><b>Open Source Projects</b><ul><li><a href=https://github.com/brk0v/trixter/tree/main>• trixter chaos proxy</a></li><li><a href=https://crates.io/crates/tokio-netem>• tokio-netem</a></li></ul></div><ul><li><a href=https://twitter.com/brk0v/ target=_blank rel=noopener><i class="bi bi-twitter"></i>
Twitter</a></li><li><a href=https://www.linkedin.com/in/biriukov/ target=_blank rel=noopener><i class="bi bi-linkedin"></i>
Linkedin</a></li><li><a href=https://github.com/brk0v/ target=_blank rel=noopener><i class="bi bi-github"></i>
Github</a></li></ul><div style=margin-top:30px><p xmlns:cc=http://creativecommons.org/ns#>This content is licensed under
<a href="http://creativecommons.org/licenses/by-nc/4.0/?ref=chooser-v1" target=_blank rel="license noopener noreferrer" style=display:inline-block>CC BY-NC 4.0<img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"></a></p></div></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Essential Linux Page Cache theory</strong>
<label for=toc-control></label></div></header><article class="markdown book-article"><h1 id=essential-page-cache-theory>Essential Page Cache theory
<a class=anchor href=#essential-page-cache-theory>#</a></h1><p class=updated-right><i><time datetime=2025-10>Last updated: Oct 2025</time></i></p><p><strong>Contents</strong></p><ul><li><a href=/docs/page-cache/2-essential-page-cache-theory/#read-requests>Read requests</a></li><li><a href=/docs/page-cache/2-essential-page-cache-theory/#write-requests>Write requests</a></li></ul><hr><p>First of all, let’s start with a bunch of reasonable questions about Page Cache:</p><ul><li>What is the <strong>Linux Page Cache</strong>?</li><li>What problems does it solve?</li><li>Why do we call it <strong>«Page»</strong> Cache ?</li></ul><p>In essence, the Page Cache is a part of the Virtual File System (<a href=https://en.wikipedia.org/wiki/Virtual_file_system target=_blank rel=noopener>VFS</a>) whose primary purpose, as you can guess, is improving the IO latency of read and write operations. A write-back cache algorithm is a core building block of the Page Cache.</p><blockquote class="book-hint info"><p><strong>NOTE</strong></p><p>If you&rsquo;re curious about the write-back algorithm (and you should be), it&rsquo;s well described on <a href=https://en.wikipedia.org/wiki/Cache_%28computing%29#Writing_policies target=_blank rel=noopener>Wikipedia</a>, and I encourage you to read it or at least look at the figure with a flow chart and its main operations.</p></blockquote><p>&ldquo;Page&rdquo; in the Page Cache means that linux kernel works with memory units called pages. It would be cumbersome and hard to track and manage bites or even bits of information. So instead, Linux&rsquo;s approach (and not only Linux&rsquo;s, by the way) is to use pages (<strong>usually <code>4K</code> in length)</strong> in almost all structures and operations. Hence the minimal unit of storage in Page Cache is a page, and it doesn&rsquo;t matter how much data you want to read or write. All file IO requests are aligned to some number of pages.</p><p>The above leads to the important fact that <strong>if your write is smaller than the page size, the kernel will read the entire page before your write can be finished</strong>.</p><p>The following figure shows a bird&rsquo;s-eye view of the essential Page Cache operations. I broke them down into reads and writes.</p><img alt="Linux Page Cache (pagecache) reads and writes" src=../images/page-cache.png width=80% class=img-center><div class=text-center>Figure 1. – Linux Page Cache (pagecache) reads and writes</div><p>As you can see, all data reads and writes go through Page Cache. However, there are some exceptions for <code>Direct IO</code> (<code>DIO</code>), and I&rsquo;m talking about it at the end of the series. For now, we should ignore them.</p><blockquote class="book-hint info"><p><strong>NOTE</strong></p><p>In the following chapters, I&rsquo;m talking about <code>read()</code>, <code>write()</code>, <code>mmap()</code> and other syscalls. And I need to say, that some programming languages (for example, Python) have file functions with the same names. However, these functions don&rsquo;t map <em>exactly</em> to the corresponding system calls. Such functions usually perform buffered IO. Please, keep this in mind.</p></blockquote><h2 id=read-requests>Read requests
<a class=anchor href=#read-requests>#</a></h2><p>Generally speaking, reads are handled by the kernel in the following way:</p><p>① – When a user-space application wants to read data from disks, it asks the kernel for data using special system calls such as <code>read()</code>, <code>pread()</code>, <code>vread()</code>, <code>mmap()</code>, <code>sendfile()</code>, etc.</p><p>② – Linux kernel, in turn, checks whether the pages are present in Page Cache and immediately returns them to the caller if so. As you can see kernel has made 0 disk operations in this case.</p><p>③ – If there are no such pages in Page Cache, the kernel must load them from disks. In order to do that, it has to find a place in Page Cache for the requested pages. A memory reclaim process must be performed if there is no free memory (in the caller&rsquo;s cgroup or system). Afterward, kernel schedules a read disk IO operation, stores the target pages in the memory, and finally returns the requested data from Page Cache to the target process. Starting from this moment, any future requests to read this part of the file (no matter from which process or cgroup) will be handled by Page Cache without any disk IOP until these pages have not been evicted.</p><h2 id=write-requests>Write requests
<a class=anchor href=#write-requests>#</a></h2><p>Let&rsquo;s repeat a step-by-step process for writes:</p><p>(Ⅰ) – When a user-space program wants to write some data to disks, it also uses a bunch of syscalls, for instance: <code>write()</code>, <code>pwrite()</code>, <code>writev()</code>, <code>mmap()</code>, etc. The one big difference from the reads is that writes are usually faster because real disk IO operations are not performed immediately. However, this is correct only if the system or a cgroup doesn&rsquo;t have memory pressure issues and there are enough free pages (we will talk about the eviction process later). So usually, the kernel just updates pages in Page Cache. it makes the write pipeline asynchronous in nature. The caller doesn’t know when the actual page flush occurs, but it does know that the subsequent reads will return the latest data. Page Cache protects data consistency across all processes and cgroups. Such pages, that contain un-flushed data have a special name: <strong>dirty pages</strong>.</p><p>(II) – If a process&rsquo; data is not critical, it can lean on the kernel and its flush process, which eventually persists data to a physical disk. But if you develop a database management system (for instance, for money transactions), you need write guarantees in order to protect your records from a sudden blackout. For such situations, Linux provides <code>fsync()</code>, <code>fdatasync()</code> and <code>msync()</code> syscalls which block until all dirty pages of the file get committed to disks. There are also <code>open()</code> flags: <code>O_SYNC</code> and <code>O_DSYNC</code>, which you also can use in order to make all file write operations durable by default. I&rsquo;m showing some examples of this logic later.</p><a href=/docs/page-cache/3-page-cache-and-basic-file-operations/ class="book-btn right-button">Read next chapter →</a></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script defer src=/my_js/copy-code.js></script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div></main><div class=cookie-container><p>This website uses "<b>cookies</b>".
Using this website means you're OK with this.
If you are <b>NOT</b>, please close the site page.</p><button class=cookie-btn>
ACCEPT AND CLOSE</button></div><script src=/my_js/cookie.js></script></body></html>