<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Cgroup v2 and Page Cache #  The cgroup subsystem is the way to fairly distribute and limit system resources. It organizes all data in a hierarchy where the leave nodes depend on their parents and inherit their settings. In additional, the cgroup provides a lot of useful resource counters and statistics. The control groups are everywhere. Even though you don&rsquo;t use it explicitly, it&rsquo;s already become turned on by default in all modern GNU/Linux distributives and got integrated in sysytemd.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="6. Cgroup v2" />
<meta property="og:description" content="Cgroup v2 and Page Cache #  The cgroup subsystem is the way to fairly distribute and limit system resources. It organizes all data in a hierarchy where the leave nodes depend on their parents and inherit their settings. In additional, the cgroup provides a lot of useful resource counters and statistics. The control groups are everywhere. Even though you don&rsquo;t use it explicitly, it&rsquo;s already become turned on by default in all modern GNU/Linux distributives and got integrated in sysytemd." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://biriukov.dev/docs/page-cache/6-cgroup-v2-and-page-cache/" /><meta property="article:section" content="docs" />



<title>6. Cgroup v2 | Viacheslav Biriukov</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.46181bc93375ba932026e753b37c40e6ff8bb16a9ef770c78bcc663e4577b1ba.css" integrity="sha256-RhgbyTN1upMgJudTs3xA5v&#43;LsWqe93DHi8xmPkV3sbo=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.6907311f0328b69e7b317a6148e3ad31f59b502749271384ef2652758a4316d2.js" integrity="sha256-aQcxHwMotp57MXphSOOtMfWbUCdJJxOE7yZSdYpDFtI=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-599VSLESJL"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-599VSLESJL');
</script>

<link rel="stylesheet" href="/my_css/cookie.css" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Viacheslav Biriukov</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Linux Page Cache series</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/0-intro/" class="">0. Intro</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/1-prepare-environment-for-experiments/" class="">1. Prepare environment</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/2-essential-page-cache-theory/" class="">2. Essential theory</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/3-page-cache-and-basic-file-operations/" class="">3. Basic file operations</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/4-page-cache-eviction-and-page-reclaim/" class="">4. Eviction and page reclaim</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/5-more-about-mmap-file-access/" class="">5. More about `mmap()`</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/6-cgroup-v2-and-page-cache/" class=" active">6. Cgroup v2</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/7-how-much-memory-my-program-uses-or-the-tale-of-working-set-size/" class="">7. Unique set and working set</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/8-direct-io-dio/" class="">8. Direct IO</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://biriukov.dev/docs/page-cache/9-advanced-page-cache-observability-and-troubleshooting-tools/" class="">9. Advanced tools</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>











  
<ul>
  
  <li>
    <a href="https://twitter.com/brk0v/" target="_blank" rel="noopener"><i class="bi bi-twitter"></i>
        Twitter
      </a>
  </li>
  
  <li>
    <a href="https://github.com/brk0v/" target="_blank" rel="noopener"><i class="bi bi-github"></i>
        Github
      </a>
  </li>
  
</ul>





<div style="margin-top: 24px;">
    <p xmlns:cc="http://creativecommons.org/ns#">This content is licensed under <a
            href="http://creativecommons.org/licenses/by-nc/4.0/?ref=chooser-v1" target="_blank"
            rel="license noopener noreferrer" style="display:inline-block; ">CC BY-NC 4.0<img
                style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img
                style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img
                style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"></a></p>
</div>
</nav>




  <script>(function(){var a=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>6. Cgroup v2</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#cgroup-v2-and-page-cache">Cgroup v2 and Page Cache</a>
      <ul>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#memory-cgroup-files">Memory cgroup files</a></li>
        <li><a href="#pressure-stall-information-psi">Pressure Stall Information (PSI)</a></li>
        <li><a href="#writeback-and-io">Writeback and IO</a></li>
        <li><a href="#memory-and-io-cgroup-ownership">Memory and IO cgroup ownership</a></li>
        <li><a href="#safe-ad-hoc-tasks">Safe ad-hoc tasks</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="cgroup-v2-and-page-cache">
  Cgroup v2 and Page Cache
  <a class="anchor" href="#cgroup-v2-and-page-cache">#</a>
</h1>
<p>The cgroup subsystem is the way to fairly distribute and limit system resources. It organizes all data in a hierarchy where the leave nodes depend on their parents and inherit their settings. In additional, the cgroup provides a lot of useful resource counters and statistics. The control groups are everywhere. Even though you don&rsquo;t use it explicitly, it&rsquo;s already become turned on by default in all modern GNU/Linux distributives and got integrated in <code>sysytemd</code>. This means that each service in a modern linux box has its own cgroup.</p>
<h2 id="overview">
  Overview
  <a class="anchor" href="#overview">#</a>
</h2>
<p>We already touched the cgroup subsystem several times during this series, but let&rsquo;s take a look at the entire picture now. The cgroup plays the critical role in Page Cache usage understanding. It also helps to debug issues and helps configure software better by providing detailed stats. As was told earlier the LRU lists use cgroup memory limits to make eviction decisions and to size the length of the LRU lists.</p>
<p>Another important topic in <a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html">cgroup v2</a>, which was unachievable with previous v1, is a proper way of tracking Page Cache IO writebacks. The v1 can&rsquo;t understand which memory cgroup generates disk IOPS and therefore it  incorrectly tracks and limits the disk operations. Fortunately, the new v2 version fixes this issues. It already provides a bunch of new features which can help with  Page Cache writeback control an thus better and more predictable performance.</p>
<p>There are some tools that you can use to navigate in the cgroup tree:</p>
<ul>
<li><code>systemd-cgls</code> and <code>systemd-top</code> to understand what cgroups <code>systemd</code> has;</li>
<li><code>below</code> a top like tool for cgroups <a href="https://github.com/facebookincubator/below">https://github.com/facebookincubator/below</a></li>
</ul>
<h2 id="memory-cgroup-files">
  Memory cgroup files
  <a class="anchor" href="#memory-cgroup-files">#</a>
</h2>
<p>Now let&rsquo;s review the most important parts of the cgroup memory controller in the perspective of Page Cache.</p>
<ol>
<li><code>memory.current</code> – shows the total amount of memory currently used by the cgroup and its descendants. It of course includes Page Cache size.</li>
</ol>
<blockquote class="book-hint info">
  <p><strong>NOTE</strong></p>
<p>It may be tempting to use it to set your cgroup/container memory limit, but wait a bit for the following chapter.</p>

</blockquote>

<ol start="2">
<li><code>memory.stat</code> – shows a lot of memory counters, the most important for us can be filtered by <code>file</code> keyword:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ grep file /sys/fs/cgroup/user.slice/user-1000.slice/session-3.scope/memory.stat
file <span style="color:#ae81ff">19804160</span>                  ❶               
file_mapped <span style="color:#ae81ff">0</span>                  ❷
file_dirty <span style="color:#ae81ff">0</span>                   ❸
file_writeback <span style="color:#ae81ff">0</span>               ❹
inactive_file <span style="color:#ae81ff">6160384</span>          ❺
active_file <span style="color:#ae81ff">13643776</span>           ❺
workingset_refault_file <span style="color:#ae81ff">0</span>      ❻
workingset_activate_file <span style="color:#ae81ff">0</span>     ❻
workingset_restore_file <span style="color:#ae81ff">0</span>      ❻
</code></pre></div><p>where</p>
<ul>
<li>❶ <code>file</code> – the size of the Page Cache;</li>
<li>❷ <code>file_mapped</code> – mapped file memory size with <code>mmap()</code>;</li>
<li>❸ <code>file_dirty</code> –  dirty pages size;</li>
<li>❹ <code>file_writeback</code> – how much data is being flushing at the moment;</li>
<li>❺ <code>inactive_file</code> and <code>active_file</code> – sizes of the LRU lists;</li>
<li>❻ <code>workingset_refault_file</code>, <code>workingset_activate_file</code> and <code>workingset_restore_file</code> – metrics to better understand memory thrashing and refault logic.</li>
</ul>
<ol start="3">
<li>
<p><code>memory.numa_stat</code> – file with the above stats but for per <a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">NUMA node</a>.</p>
</li>
<li>
<p><code>memory.min</code>, <code>memory.low</code>, <code>memory.high</code> and <code>memory.max</code> – cgroup limits. I don&rsquo;t want to repeat the <a href="https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#usage-guidelines">cgroup v2 doc</a> and recommend you to go and read it first. But what you need to keep in mind that using the hard <code>max</code> or <code>min</code> limits is not the best strategy for your applications and systems. The better approach you can choose is to set only <code>low</code> and/or <code>high</code> limits closer to what you think is the working set size of your application. We will talk about measuring and predicting it the next chapter.</p>
</li>
<li>
<p><code>memory.events</code> – shows how many times the cgroup hit the above limits:</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">emory.events
low <span style="color:#ae81ff">0</span>
high <span style="color:#ae81ff">0</span>
max <span style="color:#ae81ff">0</span>
oom <span style="color:#ae81ff">0</span>
oom_kill <span style="color:#ae81ff">0</span>
</code></pre></div><ol start="6">
<li><code>memory.pressure</code> – a file contains Pressure Stall Information (PSI). It shows the general memory health for the cgroup by measuring the CPU time that was lost due to lack of memory. This file is the key to understanding the reclaiming process in the cgroup and, consequently, Page Cache. Let&rsquo;s talk about PSI in more details.</li>
</ol>
<h2 id="pressure-stall-information-psi">
  Pressure Stall Information (PSI)
  <a class="anchor" href="#pressure-stall-information-psi">#</a>
</h2>
<p>Back before PSI times, it was hard to tell whether a system and/or a cgroup has resource contention or not, whether a cgroup limits are  overcommitted or under-provisioned. If the limit for a cgroup can be set lower, then where its threshold? The PSI feature mitigates this confusions and not only allows to get this information in realtime, but also gives an ability to setup a user-space triggers and get notifications in order to maximize hardware utilization without service degradation and OOM risks.</p>
<p>The PSI works for memory, CPU and IO controllers. For example the output for memory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">some avg10<span style="color:#f92672">=</span>0.00 avg60<span style="color:#f92672">=</span>0.00 avg300<span style="color:#f92672">=</span>0.00 total<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
full avg10<span style="color:#f92672">=</span>0.00 avg60<span style="color:#f92672">=</span>0.00 avg300<span style="color:#f92672">=</span>0.00 total<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</code></pre></div><p>where</p>
<ul>
<li><code>some</code> – means that at least one task were stalled on memory for some average percentage of wall-time during 10, 60 and 300 seconds. The &ldquo;total&rdquo; filed shows the absolute value in microseconds in order to reveal spikes;</li>
<li><code>full</code> – means the same but for all tasks in the cgroup. This metric is a good indication of issues and usually means under provisioning of the resource or wrong software settings.</li>
</ul>
<blockquote class="book-hint info">
  <p><strong>EXAMPLE</strong></p>
<p><a href="https://man7.org/linux/man-pages/man8/systemd-oomd.service.8.html"><code>systemd-oom</code></a> daemon which is a part of modern GNU/Linux systems uses the PSI to be more proactive than kernel&rsquo;s OOM in recognition of memory scarcity and finding targets for killing.</p>

</blockquote>

<p>I also highly recommend to read the original <a href="https://www.kernel.org/doc/html/latest/accounting/psi.html">PSI doc</a>.</p>
<h2 id="writeback-and-io">
  Writeback and IO
  <a class="anchor" href="#writeback-and-io">#</a>
</h2>
<p>One of the biggest feature from the cgroup v2 implementation is a possibility to track, observe and limit Page Cache async writebask for each cgroup. Nowadays the kernel writeback process can identify which cgroup IO limit to in order to flush dirty pages to disks. But what is important is that it works in another direction too. If a cgroup experiences the memory pressure and tries to reclaim some pages by flushing its dirty pages, it will use its own IO limits and won&rsquo;t harm the other cgroups. Thus the memory pressure translates to the disk IO and if there is a lot of writes, eventually to the disk pressure. Both controllers have the PSI files which should be used for proactive management and tuning your software settings.</p>
<p>In order to control dirty pages flush frequency, the linux kernel has several <a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt"><code>sysctl</code> knobs</a>. If you want, you can make the background writeback process more or less aggressive:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ sudo sysctl -a | grep dirty
vm.dirty_background_bytes <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>  
vm.dirty_background_ratio <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>  
vm.dirty_bytes <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>  
vm.dirty_expire_centisecs <span style="color:#f92672">=</span> <span style="color:#ae81ff">3000</span>  
vm.dirty_ratio <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>  
vm.dirty_writeback_centisecs <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>  
vm.dirtytime_expire_seconds <span style="color:#f92672">=</span> <span style="color:#ae81ff">43200</span>
</code></pre></div><p>Some of the above works for cgroups too. The kernel chooses and applies what reaches first for the entire system or for a cgroup.</p>
<p>The cgroup v2 also brings new IO controllers:  <code>io.cost</code> and <code>io.latency</code>. They provides 2 different approaches for limiting and guaranteeing disk operations. Please, read the cgroup v2 documentation for more details and distinctions. But I would say that if your setup is not complex, it makes sense to start with less invasive <code>io.latency</code>.</p>
<p>As with the memory controller, the kernel also provides a bunch of files to control and observe IO:</p>
<ul>
<li><code>io.stat</code> – the stat file with per device data;</li>
<li><code>io.latency</code> – the latency target time in microseconds;</li>
<li><code>io.pressure</code> – the PSI file;</li>
<li><code>io.weight</code> – the target weight if <code>io.cost</code> was chosen;</li>
<li><code>io.cost.qos</code> and <code>io.cost.model</code> – the configuration file of the <code>io.cost</code> cgroup controller.</li>
</ul>
<h2 id="memory-and-io-cgroup-ownership">
  Memory and IO cgroup ownership
  <a class="anchor" href="#memory-and-io-cgroup-ownership">#</a>
</h2>
<p>Several processes from multiple cgroups can obviously work with the same files. For example, <code>cgroup1</code> can open and read the first 10 KiB of the file, and at some moment later another <code>cgroup2</code> can append 2 KiB to the end of the same file and reads the first 4KiB. The question is whose memory and IO limits will kernel use?</p>
<p>The logic of memory ownership (therefore and Page Cache) is built on the basis of each page. The ownership of a page is charged on the first access (page fault) and won&rsquo;t switch to any other cgroup until this page will be completely reclaimed and evicted. The term ownership means that these pages will be used to calculate the cgroup Page Cache usage and will be included in all stats.</p>
<p>For our example <code>cgroup1</code> is the owner of the first 10KiB, and <code>cgroup2</code> – is the owner for the last 2KiB. No matter what <code>cgroup1</code> will do with the file, it can even close it, <code>cgroup1</code> remains the owner of the first 4KiB (not all 10KiB) as long as <code>cgroup2</code> works with these first 4KiB of the file. In this situation kernel keeps the pages in Page Caches and keeps updating LRU lists accordingly.</p>
<p>For the cgroup IO, ownership works per inode. So for our example <code>cgroup2</code> owns all writeback operations for the file. The inode is assigned to the cgroup on the first writeback, but unlike the memory pages ownership logic, the IO ownership may migrate to another cgroup if kernel notices that another cgroup generates more dirty pages.</p>
<p>In order to troubleshoot memory ownership we should use the pair of <code>procfs</code> files: <code>/proc/pid/pagemap</code> and <code>/proc/kpagecgroup</code>. The <code>page-type</code> tool also supports showing per page cgroup information, but it&rsquo;s hard to use it for a directory of files or get well formatted output, that&rsquo;s why I wrote my own <a href="https://github.com/brk0v/cgtouch"><code>cgtouch</code></a> tool in order to troubleshoot cgroup memory ownership.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ sudo go run ./main.go /var/tmp/ -v
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">/var/tmp/file1.db
cgroup inode    percent       pages        path
           -      85.9%       <span style="color:#ae81ff">28161</span>        not charged
        <span style="color:#ae81ff">1781</span>      14.1%        <span style="color:#ae81ff">4608</span>        /sys/fs/cgroup/user.slice/user-1000.slice/session-3.scope

--
/var/tmp/ubuntu-21.04-live-server-amd64.iso
cgroup inode    percent       pages        pat
           -       0.0%           <span style="color:#ae81ff">0</span>        not charged
        <span style="color:#ae81ff">2453</span>     100.0%       <span style="color:#ae81ff">38032</span>        /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-u10.service

--
         Files: <span style="color:#ae81ff">2</span>
   Directories: <span style="color:#ae81ff">7</span>
Resident Pages: 42640/70801 166.6M/276.6M 60.2%

cgroup inode    percent       pages        path
           -      39.8%       <span style="color:#ae81ff">28161</span>        not charged
        <span style="color:#ae81ff">1781</span>       6.5%        <span style="color:#ae81ff">4608</span>        /sys/fs/cgroup/user.slice/user-1000.slice/session-3.scope
        <span style="color:#ae81ff">2453</span>      53.7%       <span style="color:#ae81ff">38032</span>        /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-u10.service
</code></pre></div><h2 id="safe-ad-hoc-tasks">
  Safe ad-hoc tasks
  <a class="anchor" href="#safe-ad-hoc-tasks">#</a>
</h2>
<p>Let&rsquo;s assume we need to run the <code>wget</code> command or manually install some packages by calling a configuration management system (e.g. <code>saltstack</code>). Both these tasks may be unpredictably disks IO heavy. In order to run them safely and not interact with any production load, we should not run them in the root cgroup or terminal cgroup without any limits. It would be very tedious and cumbersome to manually create a cgroup for your task and manually configure it for every ad-hoc task. But fortunately, we don&rsquo;t have to, as so all modern GNU/Linux distros come with the <code>systemd</code> out of the box and enabled by default cgroup v2. The <code>systemd-run</code> with a lot of other cool features from <code>systemd</code> make our life easer and save a lot of time.</p>
<p>So, for example <code>wget</code> task can be run in the following manner:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">systemd-run --user -P -t -G --wait -p MemoryMax<span style="color:#f92672">=</span>12M wget http://ubuntu.ipacct.com/releases/21.04/ubuntu-21.04-live-server-amd64.iso
Running as unit: run-u2.service                         ⬅  LOOK HERE
Press ^<span style="color:#f92672">]</span> three times within 1s to disconnect TTY.
--2021-09-11 19:53:33--  http://ubuntu.ipacct.com/releases/21.04/ubuntu-21.04-live-server-amd64.iso
Resolving ubuntu.ipacct.com <span style="color:#f92672">(</span>ubuntu.ipacct.com<span style="color:#f92672">)</span>... 195.85.215.252, 2a01:9e40::252
Connecting to ubuntu.ipacct.com <span style="color:#f92672">(</span>ubuntu.ipacct.com<span style="color:#f92672">)</span>|195.85.215.252|:80... connected.
HTTP request sent, awaiting response... <span style="color:#ae81ff">200</span> OK
Length: <span style="color:#ae81ff">1174243328</span> <span style="color:#f92672">(</span>1.1G<span style="color:#f92672">)</span> <span style="color:#f92672">[</span>application/octet-stream<span style="color:#f92672">]</span>
Saving to: ‘ubuntu-21.04-live-server-amd64.iso.5’
...
</code></pre></div><p>The <code>run-u2.service</code> is my brand new memory limited cgroup, from which I can get all metrics:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ find /sys/fs/cgroup/ -name run-u2.service
/sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-u2.service
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ cat  /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-u2.service/memory.pressure
some avg10<span style="color:#f92672">=</span>0.00 avg60<span style="color:#f92672">=</span>0.00 avg300<span style="color:#f92672">=</span>0.00 total<span style="color:#f92672">=</span><span style="color:#ae81ff">70234</span>
full avg10<span style="color:#f92672">=</span>0.00 avg60<span style="color:#f92672">=</span>0.00 avg300<span style="color:#f92672">=</span>0.00 total<span style="color:#f92672">=</span><span style="color:#ae81ff">69717</span>
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ grep file  /sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/app.slice/run-u2.service/memory.stat
file <span style="color:#ae81ff">11100160</span>
file_mapped <span style="color:#ae81ff">0</span>
file_dirty <span style="color:#ae81ff">77824</span>
file_writeback <span style="color:#ae81ff">0</span>
file_thp <span style="color:#ae81ff">0</span>
inactive_file <span style="color:#ae81ff">5455872</span>
active_file <span style="color:#ae81ff">5644288</span>
workingset_refault_file <span style="color:#ae81ff">982</span>
workingset_activate_file <span style="color:#ae81ff">0</span>
workingset_restore_file <span style="color:#ae81ff">0</span>
</code></pre></div><p>As you can see from the above we have near 12MiB file memory and some refault.</p>
<p>To get all power of systemd and cgroup please read its <a href="https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html">resource control doc</a>.</p>




  

<a  href="/docs/page-cache/7-how-much-memory-my-program-uses-or-the-tale-of-working-set-size/"   class="book-btn right-button">
  Read next chapter →
</a>

</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function a(c){const a=window.getSelection(),b=document.createRange();b.selectNodeContents(c),a.removeAllRanges(),a.addRange(b)}document.querySelectorAll("pre code").forEach(b=>{b.addEventListener("click",function(c){a(b.parentElement),navigator.clipboard&&navigator.clipboard.writeText(b.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#cgroup-v2-and-page-cache">Cgroup v2 and Page Cache</a>
      <ul>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#memory-cgroup-files">Memory cgroup files</a></li>
        <li><a href="#pressure-stall-information-psi">Pressure Stall Information (PSI)</a></li>
        <li><a href="#writeback-and-io">Writeback and IO</a></li>
        <li><a href="#memory-and-io-cgroup-ownership">Memory and IO cgroup ownership</a></li>
        <li><a href="#safe-ad-hoc-tasks">Safe ad-hoc tasks</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
<div class="cookie-container">
    <p>
        This website uses "<b>cookies</b>".
        Using this website means you're OK with this.
        If you are <b>NOT</b>, please close the site page.
    </p>
    <button class="cookie-btn">
        ACCEPT AND CLOSE
    </button>
</div>
<script src="/my_js/cookie.js"></script>
</body>
</html>












